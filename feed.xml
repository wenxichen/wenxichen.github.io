<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-02-10T01:05:31-08:00</updated><id>/</id><title type="html">wenxi’s blog</title><subtitle>A site for my technicle thoughts and ideas evolved around AI technology.</subtitle><entry><title type="html">Thoughts on vertical integration</title><link href="/inspirations/2018/02/10/vertical-integration.html" rel="alternate" type="text/html" title="Thoughts on vertical integration" /><published>2018-02-10T00:50:44-08:00</published><updated>2018-02-10T00:50:44-08:00</updated><id>/inspirations/2018/02/10/vertical-integration</id><content type="html" xml:base="/inspirations/2018/02/10/vertical-integration.html">&lt;p&gt;Imagine taking an airplane, one would not need to know how to build it before sitting comfortable in it. Similarly, a pilot need not to know how each part of the plane works mechanically, a mechanic need not to know how each tool is created, and a software engineer need not to know the blueprint of his/her computer chips. Thus, for every complicate system there are different levels of abstraction. Each level is build on top of the previous one. Moreover, it seems to be easier to build level x+1 using level x rather than level x-1.&lt;/p&gt;

&lt;p&gt;However, one may argue that everything can be explained or constructed using only the very low level components (e.g., atom level), except that it is almost impossible for us to comprehend a holistic view using only the lower level components. By introducing higher level abstractions, we make communication of ideas and knowledge more efficiently. Essentially, we create embedding to reduce the computation cost for ourselves to think and imagine, and to reduce the bandwidth need for us to communicate. But, at the same time, such compression also introduce noise.&lt;/p&gt;

&lt;p&gt;On the other hand, machines have perfect memory and potentially more computation power. So, is it possible that in future machine learning we can abandon the higher level abstractions? Obviously, current approaches still embrace the structure information and the idea of embedding and adding levels of abstraction (e.g., 100+ layer CONV Nets). But do we really need it? If we do so much computation and achieve optimization using genetic programming, why can’t we have a “vertical integration” of abstractions and learn everything at the atom level? In that case, we create less noise and higher accuracy.&lt;/p&gt;

&lt;p&gt;One note to myself is that structural information may not equal to high level of abstraction. For example, by processing an image using a 2D/3D array instead of a 1D array, we preserve information rather than introducing a higher level of abstraction.&lt;/p&gt;

&lt;p&gt;(TODO: Need to write an example in CNN…)&lt;/p&gt;</content><author><name></name></author><summary type="html">Imagine taking an airplane, one would not need to know how to build it before sitting comfortable in it. Similarly, a pilot need not to know how each part of the plane works mechanically, a mechanic need not to know how each tool is created, and a software engineer need not to know the blueprint of his/her computer chips. Thus, for every complicate system there are different levels of abstraction. Each level is build on top of the previous one. Moreover, it seems to be easier to build level x+1 using level x rather than level x-1.</summary></entry><entry><title type="html">Inspirations from Worms at NIPS2017</title><link href="/inspirations/2017/12/27/nips-2017-inspirations.html" rel="alternate" type="text/html" title="Inspirations from Worms at NIPS2017" /><published>2017-12-27T20:50:44-08:00</published><updated>2017-12-27T20:50:44-08:00</updated><id>/inspirations/2017/12/27/nips-2017-inspirations</id><content type="html" xml:base="/inspirations/2017/12/27/nips-2017-inspirations.html">&lt;p&gt;NIPS2017 is my first time to the conference. I would like to share some thoughts and inspirations from the &lt;a href=&quot;https://sites.google.com/site/wwnip2017/home&quot;&gt;Workshop on Worm’s Neural Information Processing&lt;/a&gt;. Hopefully it would be useful for others’ research.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Caenorhabditis_elegans&quot;&gt;C. Elegans&lt;/a&gt; is a worm species. What’s special about it is that all of its neurons have been completely mapped out. Although the worm only has 302 neurons, it can perform most things animals do - navigating, mating, finding food etc. So the Workshop on Worm’s Neural Information Processing tried to bridge between the neural science research on C. Elegans and machine learning. I personally had never heard about C. Elegans before the workshop. But the workshop turned out to be really interesting and inspiring. Below are some interesting points the great speakers came across that I found not entirely consistent with the current popular design of machine learning models, thus worth sharing.&lt;/p&gt;

&lt;h1 id=&quot;sensory-layer-does-more-than-embedding&quot;&gt;Sensory layer does more than embedding&lt;/h1&gt;
&lt;p&gt;Professor Netta Cohen gave a talk about C. Elegans search for salt. She showed that the sensory layer in C. Elegans is adaptive to its experience. So the simple example was that if the worm is on salt, it will become less attracted to salt; if it is not around salt any more, it will become attracted by salt again. As a result, there seems to be recurrent computation between the internal sensory states. This kind of computation certainly is doing more than embedding. Indeed, they did some experiment on pothole detection using a simulated adaptive navigation [1].&lt;/p&gt;

&lt;h1 id=&quot;activation-may-be-distributed-to-more-than-one-neurons&quot;&gt;Activation may be distributed to more than one neurons&lt;/h1&gt;
&lt;p&gt;Dr. William R. Schafer gave a talk about the effect of removing neurons on C. Elegans’ muscle control. They found different types of mapping between neurons to the muscle movement. Some neuron is necessary to certain movement, while some other neuron is not individually necessary. It is not clear why the differences, but it is definitely worth looking into. However, I realize this is not inconsistent with MLP where the effect of removal of certain neuron on activation depends on the weight. Abstract of the paper on this topic can be found here [2].&lt;/p&gt;

&lt;h1 id=&quot;recurrent-structure-of-neurons&quot;&gt;Recurrent structure of neurons&lt;/h1&gt;
&lt;p&gt;Professor Radu Grosu presented his team’s work on robot parking with worm inspired neural networks. There are two things make this neural network design really interesting. The first is that the network only has about 10 neurons. Secondly, each neuron is like a flip-flop. There are recurrent computations within groups of neurons and also from a single neuron direct back to itself. The network was trained using some genetic algorithms. But Ramin M. Hasani and Mathias Lechner (both are contributors to this work) mentioned they implemented this on tensorflow using some gradient method which increased the training speed significantly.&lt;/p&gt;

&lt;p&gt;It seems the recurrent structure can really help with reducing the number of neurons. I believe the team will publish their work soon (hopefully the code as well). I can’t wait to read more about this.&lt;/p&gt;

&lt;h1 id=&quot;holistic-design-in-biology&quot;&gt;Holistic design in Biology&lt;/h1&gt;
&lt;p&gt;Another interesting issue pointed out during the final panel discussion is that the neurons and body of an organism are usually highly synchronized with each other. Maybe this is not something we need to concern if we just want to design a model that does not control a body. But if it is an intelligent system for a robot, it may be worth thinking about what constitutes this synergy and what’s the benefit of it.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Although I don’t think AI will be designed exactly the same way as any existing living organism, the work of nature can still give us a lot of inspirations. I remember hearing the argument that to achieve what human can do we should start small to achieve what a rat can do first. Thus, it may worth a while looking into C. Elegans first.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;A C. elegans inspired robotic model for pothole detection [&lt;a href=&quot;https://docs.google.com/viewer?a=v&amp;amp;pid=sites&amp;amp;srcid=ZGVmYXVsdGRvbWFpbnx3d25pcDIwMTd8Z3g6YTg4YzA5YTViMzRhMWNm&quot;&gt;link&lt;/a&gt;]&lt;/p&gt;

    &lt;p&gt;John Lones, Anthony G Cohn, Netta Cohen&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Using network control principles to probe the structure and function of neuronal connectomes [&lt;a href=&quot;https://docs.google.com/viewer?a=v&amp;amp;pid=sites&amp;amp;srcid=ZGVmYXVsdGRvbWFpbnx3d25pcDIwMTd8Z3g6ZTRjNGYzMTMxMWZlYzQ3&quot;&gt;abstract&lt;/a&gt;]&lt;/p&gt;

    &lt;p&gt;William R. Schafer, Gang Yan, et al.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">NIPS2017 is my first time to the conference. I would like to share some thoughts and inspirations from the Workshop on Worm’s Neural Information Processing. Hopefully it would be useful for others’ research.</summary></entry></feed>