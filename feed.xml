<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2017-12-26T23:23:04-05:00</updated><id>/</id><title type="html">wenxi’s blog</title><subtitle>A site for my technicle thoughts and ideas evolved around AI technology.</subtitle><entry><title type="html">Inspirations from Worms and Interpretability from NIPS2017</title><link href="/inspirations/2017/12/24/nips-2017-inspirations.html" rel="alternate" type="text/html" title="Inspirations from Worms and Interpretability from NIPS2017" /><published>2017-12-24T23:50:44-05:00</published><updated>2017-12-24T23:50:44-05:00</updated><id>/inspirations/2017/12/24/nips-2017-inspirations</id><content type="html" xml:base="/inspirations/2017/12/24/nips-2017-inspirations.html">&lt;p&gt;This is my first NIPS. I would like to share some thoughts and inspiration without going too much into the technical stuff. More specifically, my thoughts are mainly on the worm C. Elegans workshop and interpretability. Hopefully it would be useful for others’ research.&lt;/p&gt;

&lt;h1 id=&quot;on-c-elegans&quot;&gt;On C. Elegans&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Caenorhabditis_elegans&quot;&gt;C. Elegans&lt;/a&gt; is a worm species. What’s special about it is that all of its neurons have been completely mapped out. So &lt;a href=&quot;https://sites.google.com/site/wwnip2017/home&quot;&gt;Workshop on Worm’s Neural Information Processing&lt;/a&gt; tries to bridge between the neural science research on C. Elegans and machine learning. I personally have never heard about C. Elegans before the workshop. But the workshop turned out to be really interesting and inspiring. Below are some interesting points the great speakers come across that I find not entirely consistent with current popular design of machine learning models.&lt;/p&gt;

&lt;h3 id=&quot;sensory-layer-does-more-than-embedding&quot;&gt;Sensory layer does more than embedding&lt;/h3&gt;
&lt;p&gt;Professor Netta Cohen from University of Leeds gave a talk about C. Elegans search for salt. She argues that the sensory layer in C. Elegans is adaptive to its experience. So the simple example is that if the worm is on salt, it will become less attracted to salt; if it is not around salt any more, it will become attracted by salt again. As a result, there may be recurrent computation between the internal sensory states. It seems this kind of research may be useful for the autonomous driving research. Indeed, they did some experiment on pothole detection [1].&lt;/p&gt;

&lt;p&gt;Interpretability:&lt;/p&gt;

&lt;p&gt;C. Elegans workshop:&lt;/p&gt;

&lt;p&gt;Representations:&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;A C. elegans inspired robotic model for pothole detection [&lt;a href=&quot;https://docs.google.com/viewer?a=v&amp;amp;pid=sites&amp;amp;srcid=ZGVmYXVsdGRvbWFpbnx3d25pcDIwMTd8Z3g6YTg4YzA5YTViMzRhMWNm&quot;&gt;link&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;John Lones, Anthony G Cohn, Netta Cohen&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">This is my first NIPS. I would like to share some thoughts and inspiration without going too much into the technical stuff. More specifically, my thoughts are mainly on the worm C. Elegans workshop and interpretability. Hopefully it would be useful for others’ research.</summary></entry></feed>